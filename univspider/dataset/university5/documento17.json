{
  "id": 5,
  "date": "2024-05-18T18:23:10.319688",
  "url": "https://www.cs.jhu.edu/department-seminars/",
  "university_name": "Johns Hopkins University",
  "title": "Secondary Navigation",
  "content": "Skip to main content Skip to site alert Secondary Navigation CS IT Support Menu ﻿ Close ﻿ Search ﻿ Info For ﻿ Close ﻿ Info For Navigation CS IT Support Resources for Undergrads Resources for Graduate Students Employers ﻿ Department of Computer Science Department of Computer Science Utility Navigation Request Info ﻿ Apply ﻿ Give ﻿ Site Navigation About Message from the Department Head Diversity and Inclusion Employment Opportunities Academic Programs Accreditation & Enrollment Undergraduate Studies Graduate Studies Combined Bachelor’s/Master’s Academic Integrity Code Research Theory & Programming Languages Systems & Networking Computational Biology & Medicine Information Security Natural Language Processing Machine Learning, AI, & Data Science Robotics, Vision, & Graphics Human-Computer Interaction Computer-Assisted Medicine People Faculty Joint, Affiliate, & Research Faculty Staff PhD Students External Advisory Board News CS Newsletter Events Department Seminars Join our Seminar Listserv CS Distinguished Lecture Series Alumni & Giving Search ﻿ Info For ﻿ Close ﻿ Info For Navigation CS IT Support Resources for Undergrads Resources for Graduate Students Employers ﻿ You are here: Home Department Seminars Department Seminars The Department of Computer Science is proud to welcome esteemed speakers to Johns Hopkins University Homewood campus for our department seminar series. Play background animation Pause background animation Details: WHERE: Hackerman B-17, unless otherwise noted WHEN: 10:30 a.m. refreshments available, seminar runs from 10:45 a.m. to 12 p.m., unless otherwise noted Recordings will be available online after each seminar. Schedule of Speakers Click to expand for talk title, abstract, and speaker biography. TBD Tommi S. Jaakkola Massachusetts Institute of Technology Zoom link >> Computer Science Seminar Series “ Generative AI for (Molecular) Sciences ” Abstract: Massive efforts are under way to develop and adapt generative AI to solve any and all inferential and design tasks across engineering and science disciplines. Framing or reframing problems in terms of distributional modeling can bring a number of benefits, but also comes with substantial technical and statistical challenges. Tommi S. Jaakkola’s work has focused on advancing machine learning methods for controlled generation of complex objects, ranging from molecular interactions (e.g., docking) and 3D structures to new materials tailored to exhibit desirable characteristics such as carbon capture. In this talk, Jaakkola will cover a few research vignettes along with their specific challenges, focusing on diffusion and flow models that surpass traditional or alternative approaches to docking, protein design, or conformational ensembles. Time permitting, he will highlight general challenges and opportunities in this area. Speaker Biography: Tommi S. Jaakkola is the Thomas Siebel Professor of Electrical Engineering and Computer Science in the Massachusetts Institute of Technology’s Department of Electrical Engineering and Computer Science and the MIT Institute for Data, Systems, and Society; he is also an investigator at the MIT Computer Science and Artificial Intelligence Laboratory. He is a fellow of the Association for the Advancement of Artificial Intelligence with many awards for his publications. His research covers how machines can learn, generate, or control and do so at scale in an efficient, principled, and interpretable manner, from foundational theory to modern design challenges. Over the past several years, Jaakkola’s applied work has been focused on molecular modeling and design. Past Speakers Click to expand for recording, date, abstract, and speaker biography. Paths to AI Accountability Sarah Cen, Massachusetts Institute of Technology View the recording >> Computer Science Seminar Series April 25, 2024 Abstract: We have begun grappling with difficult questions related to the rise of AI, including: What rights do individuals have in the age of AI? When should we regulate AI and when should we abstain? What degree of transparency is needed to monitor AI systems? These questions are all concerned with AI accountability. In this talk, Sarah Cen discusses the two components of her research on AI accountability and illustrates them through a case study on auditing social media. Within the context of social media, she will focus on how social media platforms filter (or curate) the content that users see. In particular, Cen will propose a way to implement regulations on social media that is compatible with free speech protections and Section 230. She will then present a way to test whether a content curation algorithm complies with regulations, producing what we call a “counterfactual audit.” In studying the properties of this approach, she will show that it has strong theoretical guarantees, does not violate user privacy, and uses only black-box access to the algorithm (thereby requiring minimal access to proprietary algorithms and data). She will demonstrate how this audit can be applied in practice using LLMs on a live social media platform. Speaker Biography: Sarah Cen is a final-year PhD student in the Massachusetts Institute of Technology’s Department of Electrical Engineering and Computer Science, where she is advised by Professors Aleksander Mądry and Devavrat Shah. Cen utilizes methods from machine learning, statistical inference, causal inference, and game theory to study responsible computing and AI policy. Previously, she has written about social media, trustworthy algorithms, algorithmic fairness, and more. She is currently interested in AI auditing, AI supply chains, and the intellectual property rights of data providers. What's Wrong with Large Language Models and What We Should Be Building Instead Tom Dietterich, Oregon State University View the recording >> Institute for Assured Autonomy & Computer Science Seminar Series April 16, 2024 Abstract: Large language models provide a pre-trained foundation for training many interesting AI systems. However, they have many shortcomings: They are expensive to train and to update, their non-linguistic knowledge is poor, they make false and self-contradictory statements, and these statements can be socially and ethically inappropriate. This talk will review these shortcomings and current efforts to address them within the existing LLM framework. It will then argue for a different, more modular architecture that decomposes the functions of existing LLMs and adds several additional components. We believe this alternative can address many of the shortcomings of LLMs. Speaker Biography: Tom Dietterich (AB Oberlin College 1977; MS University of Illinois 1979; PhD Stanford University 1984) is Distinguished Professor Emeritus in the School of Electrical Engineering and Computer Science at Oregon State University. Dietterich is one of the pioneers of the field of machine learning and has authored more than 200 refereed publications and two books. He is a fellow of the ACM, the American Association for the Advancement of Science, and the Association for the Advancement of Artificial Intelligence . His current research topics include robust artificial intelligence, robust human-AI systems, and applications in sustainability. Structured World Models for Robots Krishna Murthy, Massachusetts Institute of Technology View the recording >> Computer Science Seminar Series April 12, 2024 Abstract: Humans have an innate ability to construct detailed mental representations of the world from limited sensory data. These “world models” are central to natural intelligence, allowing us to perceive, reason about, and act in the physical world. Krishna Murthy’s research seeks to create “computational world models”—artificial intelligence techniques that enable robots to understand and operate in the world around as effectively as humans. Despite the impressive successes of modern machine learning approaches in media such as text, images, and video—where abundant training data is readily available—these advancements have not translated to robotics. Building generally capable robotic systems presents unique challenges, including this lack of data and the need to adapt learning algorithms to a wide variety of embodiments, environments, and tasks of interest. In his talk, Murthy will present how his research contributes to the design of computational models for spatial, physical, and multimodal understanding. He will discuss differentiable computing approaches that have advanced the field of spatial perception, enabling an understanding of the structure of the 3D world, its constituent objects, and their semantic and physical properties from videos. He will also detail how his work interfaces advances in large image, language, and audio models with 3D scenes, enabling robots and computer vision systems to flexibly query these structured world models for a wide range of tasks. Finally, he will outline his vision for the future, where structured world models and modern scaling-based approaches work in tandem to create versatile robot perception and planning algorithms with the potential to meet and ultimately surpass human-level capabilities. Speaker Biography: Krishna Murthy is a postdoctoral researcher at the Massachusetts Institute of Technology working with Antonio Torralba and Josh Tenenbaum. He previously completed his PhD at Mila and the University of Montreal, where he was advised by Liam Paull. Murthy’s research focuses on building computational world models to help embodied agents perceive, reason about, and act in the physical world. He has led the organization of multiple workshops on themes spanning differentiable programming, physical reasoning, 3D vision and graphics, and ML research dissemination. His research has been recognized with graduate fellowship awards from NVIDIA and Google (2021); a Best Paper Award from the Institute of Electrical and Electronics Engineers’ Robotics and Automation Letters (2019); and an induction to the Robotics: Science and Systems Pioneers cohort (2020). Robot Navigation in Complex Indoor and Outdoor Environments Dinesh Manocha, University of Maryland, College Park View the recording >> Computer Science Seminar Series April 11, 2024 Abstract: In the last few decades, most robotics success stories have been limited to structured or controlled environments. A major challenge is to develop robot systems that can operate in complex or unstructured environments corresponding to homes, dense traffic, outdoor terrains, public places, etc. In this talk, Dinesh Manocha gives an overview of his ongoing work on developing robust planning and navigation technologies that use recent advances in computer vision, sensor technologies, machine learning, and motion planning algorithms. He presents new methods that utilize multimodal observations from an RGB camera, 3D LiDAR, and robot odometry for scene perception, along with deep reinforcement learning  for reliable planning; the latter is also used to compute dynamically feasible and spatially aware velocities for a robot navigating among mobile obstacles and uneven terrains. These methods have been integrated with wheeled robots, home robots, and legged platforms and their performance has been highlighted in crowded indoor scenes, home environments, and dense outdoor terrains. Speaker Biography: Dinesh Manocha is the Paul Chrisman Iribe Professor of Computer Science and Electrical and Computer Engineering and a Distinguished University Professor at the University of Maryland, College Park. His research interests include virtual environments, physically based modeling, and robotics. His group has developed a number of software packages that are standard and licensed to 60+ commercial vendors. He has published more than 750 papers and supervised 50 PhD dissertations. He is a fellow of the Association for the Advancement of Artificial Intelligence , the American Association for the Advancement of Science, the ACM, the Institute of Electrical and Electronics Engineers (IEEE) , and the National Academy of Inventors. He is also a member of the ACM’s Special Interest Group on Computer Graphics and Interactive Techniques and the IEEE Visualization and Graphics Technical Community’s Virtual Reality Academy. Manocha is the recipient of a Pierre Bézier Award from the Solid Modeling Association, a Distinguished Alumni Award from the Indian Institute of Technology Delhi, and a Distinguished Career Award in Computer Science from the Washington Academy of Sciences. He was also a co-founder of Impulsonic, a developer of physics-based audio simulation technologies that was acquired by Valve Corporation in November of 2016. A First-Principles Approach to Deep Learning and Applications to Quantum Materials Yasaman Bahri, Google DeepMind View the recording >> Computer Science Seminar Series April 8, 2024 Abstract: Recent years have seen unprecedented advancements in the development of machine learning and artificial intelligence. For the applied sciences, these tools offer new paradigms for combining insights developed from theory, computation, and experiments towards design and discovery, and for bridging the microscopic world with the macroscopic. Beyond treating them as black boxes, however, uncovering and distilling the fundamental principles behind how systems built with neural networks work is a grand challenge, and one that can be aided by ideas, tools, and methodologies from physics. Yasaman Bahri will describe one pillar of her research that takes a first-principles approach to deep learning through the lens of statistical physics, exactly solvable models and mean-field theories, and nonlinear dynamics. She will discuss new connections she discovered between large-width deep neural networks, Gaussian processes, and kernels; the emergence of linear models during training and phase transitions away from them; experimentally-consistent insights into scaling laws; and an outlook on the next frontiers in this research program. She will then discuss the early stages of a second research program proceeding in the reverse direction, in which a deeper understanding of ML and AI can be used to advance the quantum sciences and quantum materials. As an early example, Bahri considers physics as a domain to examine recall and reasoning in large language models. She will describe work investigating the ability of such models to perform analytic Hartree-Fock mean-field calculations in quantum many-body physics. Speaker Biography: Yasaman Bahri is a research scientist at Google DeepMind. Her research lies at the confluence of machine learning and the physical sciences. She completed her PhD in physics at the University of California, Berkeley as an NSF Graduate Fellow, specializing in the theory of quantum condensed matter. Her doctoral work investigated quantum matter through the themes of topology, symmetry, and localization. She has been an invited lecturer at the Les Houches School of Physics, is a past Rising Star in Electrical Engineering and Computer Science, and was a co-organizer of a recent program on deep learning at the Kavli Institute for Theoretical Physics. SmartBook: An AI Prophetess for Disaster Reporting and Forecasting Heng Ji, University of Illinois Urbana-Champaign View the recording >> Computer Science Seminar Series April 5, 2024 Abstract: History repeats itself—sometimes in a bad way. Preventing natural or man-made disasters requires being aware of these patterns and taking preemptive action to address and reduce them—or ideally, eliminate them. Emerging events, such as the COVID pandemic and the Ukraine crisis, require a time-sensitive, comprehensive understanding of the situation to allow for appropriate decision-making and effective action response. Automated generation of situation reports can significantly reduce the time, effort, and cost for domain experts when preparing their official, human-curated reports. However, AI research toward this goal has been very limited and no successful trials have yet been conducted to automate such report generation and “what-if” disaster forecasting. Preexisting natural language processing and information retrieval techniques are insufficient to identify, locate, and summarize important information and lack detailed, structured, and strategic awareness. In this talk, Heng Ji will present SmartBook, a novel framework that cannot be solved by large language models alone to consume large volumes of multimodal multilingual news data and produce a structured situation report with multiple hypotheses (claims) summarized and grounded with rich links to factual evidence through multimodal knowledge extraction, claim detection, fact checking, misinformation detection, and factual error correction. Furthermore, SmartBook can also serve as a novel news event simulator or an intelligent prophetess. Given “what-if” conditions and dimensions elicited from a domain expert user concerning a disaster scenario, SmartBook will induce schemas from historical events and automatically generate a complex event graph along with a timeline of news articles that describe new simulated events and character-centric stories based on a new Λ-shaped attention mask that can generate text with infinite length. By effectively simulating disaster scenarios in both event graph and natural language formats, SmartBook is expected to greatly assist humanitarian workers and policymakers to exercise reality checks and thus better prevent and respond to future disasters. Speaker Biography: Heng Ji is a professor of computer science at the University of Illinois Urbana-Champaign, where she is an affiliated faculty member of the Electrical and Computer Engineering Department and the Coordinated Science Laboratory. She is an Amazon Scholar and is the founding director of the Amazon-Illinois Center on AI for Interactive Conversational Experiences. Ji received her BA and MA in computational linguistics from Tsinghua University and her MS and PhD in computer science from New York University. Her research interests focus on natural language processing—especially on multimedia multilingual information extraction, knowledge-enhanced large language Models, knowledge-driven generation, and conversational AI. Ji was selected as a Young Scientist to attend the 6th World Laureates Forum and was selected to participate in DARPA’s 2023 AI Forward initiative. She was selected as a Young Scientist and a member of the Global Future Council on the Future of Computing by the World Economic Forum in 2016 and 2017. Other awards she has received include being named a Women Leader of Conversational AI (Class of 2023) by Project Voice; an “AI’s 10 to Watch” Award by IEEE Intelligent Systems in 2013; an NSF CAREER Award in 2009; Best Paper Runner-Up at the 26th Pacific Asia Conference on Language, Information, and Computation; a Best Paper Award at the 2013 Institute of Electrical and Electronics Engineers’ (IEEE) International Conference on Data Mining; a Best Paper Award at the 2013 Society for Industrial and Applied Mathematics’ International Conference on Data Mining; a nomination for Best Demo Paper at the 2018 Annual Meeting of the Association for Computational Linguistics (ACL); a Best Demo Paper Award at ACL 2020; a Best Demo Paper Award at the 2021 Annual Conference of the North American Chapter of the ACL (NAACL); Google Research Awards in 2009 and 2014; an IBM Faculty Award in 2012 and 2014; and Bosch Research Awards in 2014 through 2018. Ji was invited to testify to the United States House of Representatives Cybersecurity, Information Technology, and Government Innovation Subcommittee as an AI expert in 2023; s he was also invited by the Secretary of the U.S. Air Force and the Air Force Research Laboratory (AFRL) to join the Department of the Air Force Data, Analytics, and AI Forum to inform Air Force Strategy in 2030 and was invited to speak at the federal Information Integrity R&D Interagency Working Group briefing in 2023. She is the lead of many multi-institution projects and tasks, including United States Army Research Laboratory (ARL) projects on information fusion and knowledge networks construction, the DARPA Environment-Driven Conceptual Learning program’s Multimodal InteRActive Conceptual Learning team, the DARPA Knowledge-directed Artificial Intelligence Reasoning Over Schemas program’s Reasoning about Event Schemas for Induction of kNowledge team, and the DARPA Deep Exploration and Filtering of Text’s Tinker Bell team. Ji coordinated the National Institute of Standards and Technology Text Analysis Conference Knowledge Base Population task from 2010 to 2022. She was the associate editor for the IEEE/ACM Transactions on Audio, Speech, and Language Processing and has served as program committee co-chair of many conferences, including the 2018 Conference of the NAACLL Human Language Technologies and 2022 Conference of the Asia-Pacific Chapter of the ACL and the International Joint Conference on Natural Language Processing. Ji was elected as the secretary of the NAACL from 2020 to 2023. Her research has been widely supported by U.S. government agencies (e.g., DARPA, NSF, the Department of Energy, ARL, the Intelligence Advanced Research Projects Activity, AFRL, the Department of Homeland Security) and industry partners (e.g., Apple, Amazon, Google, Meta, Bosch, IBM, Disney). Enforcing Right to Explanation: Algorithmic Challenges and Opportunities Himabindu Lakkaraju, Harvard University View the recording >> Computer Science Seminar Series April 4, 2024 Abstract: As predictive and generative models are increasingly being deployed in various high-stakes applications in critical domains including health care, law, policy, and finance, it is important to ensure that relevant stakeholders understand the behaviors and outputs of these models so that they can determine if and when to intervene. To this end, several techniques have been proposed in recent literature to explain these models; in addition, multiple regulatory frameworks (e.g., the General Data Protection Regulation , the California Consumer Privacy Act ) introduced in recent years also emphasize the importance of enforcing the key principle of “right to explanation” to ensure that individuals who are adversely impacted by algorithmic outcomes are provided with an actionable explanation. In this talk, Himabindu Lakkaraju will discuss the gaps that exist between regulations and state-of-the-art technical solutions when it comes to explainability of predictive and generative models. She will then present some of her latest research that attempts to address some of these gaps. She will conclude her talk by discussing bigger challenges that arise as we think about enforcing right to explanation in the context of large language models and other large generative models. Speaker Biography: Himabindu “Hima” Lakkaraju is an assistant professor at Harvard University focusing on the algorithmic, theoretical, and applied aspects of explainability, fairness, and robustness of machine learning models. Lakkaraju has been named as one of the world’s top innovators under 35 by both MIT Tech Review and Vanity Fair. She has also received several prestigious awards, including an NSF CAREER Award, an AI2050 Early Career Fellowship by Schmidt Futures, and multiple Best Paper Awards at top-tier ML conferences; she has also received grants from the NSF, Google, Amazon, J.P. Morgan, and Bayer. Lakkaraju has given keynote talks at various top ML conferences and associated workshops, including the Conference on Information and Knowledge Management, the International Conference on Machine Learning, the Conference and Workshop on Neural Information Processing Systems, the International Conference on Learning Representations, the Association for the Advancement of Artificial Intelligence, and the Conference on Computer Vision and Pattern Recognition; her research has also been showcased by popular media outlets including The New York Times, MIT Tech Review, TIME, and Forbes. More recently, she co-founded the Trustworthy ML Initiative to enable easy access to resources on trustworthy ML and to build a community of researchers and practitioners working on the topic. Model-Based Methods in Today’s Data-Driven Robotics Landscape Seth Hutchinson, Georgia Institute of Technology View the recording >> Computer Science Seminar Series April 3, 2024 Abstract: Data-driven machine learning methods are making advances in many long-standing problems in robotics, including grasping, legged locomotion, perception, and more. There are, however, robotics applications for which data-driven methods are less effective. Data acquisition can be expensive, time consuming, or dangerous—to the surrounding workspace, humans in the workspace, or the robot itself. In such cases, generating data via simulation might seem a natural recourse, but simulation methods come with their own limitations, particularly when nondeterministic effects are significant or when complex dynamics are at play, requiring heavy computation and exposing the so-called sim2real gap. Another alternative is to rely on a set of demonstrations, limiting the amount of required data by careful curation of the training examples; however, these methods fail when confronted with problems that were not represented in the training examples (so-called out-of-distribution problems) and this precludes the possibility of providing provable performance guarantees. In this talk, Seth Hutchinson will describe recent work on robotics problems that do not readily admit data-driven solutions, including flapping flight by a bat-like robot, vision-based control of soft continuum robots, a cable-driven graffiti-painting robot, and ensuring safe operation of mobile manipulators in human-robot interaction scenarios. He will describe some specific difficulties that confront data-driven methods for these problems and how model-based approaches can provide workable solutions. Along the way, he will also discuss how judicious incorporation of data-driven machine learning tools can enhance performance of these methods. Speaker Biography: Seth Hutchinson is the executive director of the Institute for Robotics and Intelligent Machines at the Georgia Institute of Technology, where he is also a professor and the KUKA Chair for Robotics in the School of Interactive Computing. Hutchinson received his PhD from Purdue University in 1988, and in 1990 he joined the University of Illinois in Urbana-Champaign, where he was a professor of electrical and computer engineering (ECE) until 2017 and served as the associate department head for ECE from 2001 to 2007. A fellow of the Institute of Electrical and Electronics Engineers (IEEE), Hutchinson served as the president of the IEEE Robotics and Automation Society (RAS) from 2020 to 2021 and has previously served as a member of the RAS Administrative Committee, as the editor-in-chief for IEEE Transactions on Robotics, and as the founding editor-in-chief of the RAS Conference Editorial Board. He has served on the organizing committees for more than 100 conferences, has more than 300 publications on the topics of robotics and computer vision, and is co-author of the books Robot Modeling and Control (Wiley), Principles of Robot Motion: Theory, Algorithms, and Implementations (MIT Press), and the forthcoming Introduction to Robotics and Perception (Cambridge University Press). Making Machine Learning Predictably Reliable Andrew Ilyas, Massachusetts Institute of Technology View the recording >> Computer Science Seminar Series April 1, 2024 Abstract: Despite machine learning models’ impressive performance, training and deploying them is currently a somewhat messy endeavor. But does it have to be? In this talk, Andrew Ilyas overviews his work on making ML “predictably reliable”—enabling developers to know when their models will work, when they will fail, and why. To begin, he uses a case study of adversarial inputs to show that human intuition can be a poor predictor of how ML models operate. Motivated by this, he presents a line of work that aims to develop a precise understanding of the ML pipeline, combining statistical tools with large-scale experiments to characterize the role of each individual design choice: from how to collect data, to what dataset to train on, to what learning algorithm to use. Speaker Biography: Andrew Ilyas is a PhD student in computer science at the Massachusetts Institute of Technology, where he is advised by Aleksander Madry and Constantinos Daskalakis. His research aims to improve the reliability and predictability of machine learning systems. He was previously supported by an Open Philanthropy AI Fellowship. Accessible Foundation Models: Systems, Algorithms, and Science Tim Dettmers, University of Washington View the recording >> Computer Science Seminar Series March 28, 2024 Abstract: The ever-increasing scale of foundation models, such as ChatGPT and AlphaFold, has revolutionized AI and science more generally. However, increasing scale also steadily raises computational barriers, blocking almost everyone from studying, adapting, or otherwise using these models for anything beyond static API queries. In this talk, Tim Dettmers will present research that significantly lowers these barriers for a wide range of use cases, including inference algorithms that are used to make predictions after training, fine-tuning approaches that adapt a trained model to new data, and finally, full training of foundation models from scratch. For inference, he will describe the LLM.int8() algorithm, which showed how to enable high-precision 8-bit matrix multiplication that is both fast and memory efficient. LLM.int8() is based on the discovery and characterization of sparse outlier sub-networks that only emerge at large model scales, but are crucial for effective Int8 quantization. For fine-tuning, he will introduce the QLoRA algorithm, which pushes such quantization much further to unlock fine-tuning of very large models on a single GPU by only updating a small set of the parameters while keeping most of the network in a new information-theoretically optimal 4-bit representation. For full training, he will present SWARM parallelism, which allows collaborative training of foundation models across continents on standard internet infrastructure while still being 80% as effective as the prohibitively expensive supercomputers that are currently used. Finally, he will close by outlining his plans to make foundation models 100x more accessible, which will be needed to maintain truly open AI-based scientific innovation as models continue to scale. Speaker Biography: Tim Dettmers’ research focuses on making foundation models, such as ChatGPT, accessible to researchers and practitioners by reducing their resource requirements. This involves developing novel compression and networking algorithms and building systems that allow for memory-efficient, fast, and cheap deep learning. These methods enable many more people to use, adapt, or train foundation models without affecting the quality of AI predictions or generations. Dettmers is a PhD candidate at the University of Washington and has won oral, spotlight, and best paper awards at conferences such as the International Conference on Learning Representations and the Conference and Workshop on Neural Information Processing Systems . He created the bitsandbytes library for efficient deep learning, which is growing at 1.4 million installations per month, and has received Google Open Source and PyTorch Foundation awards. Data-Distributional Approaches for Generalizable Language Models Sang Michael Xie, Stanford University View the recording >> Computer Science Seminar Series March 25, 2024 Abstract: High-quality datasets are crucial for improving the capabilities and training efficiency of large language models. However, current datasets are typically prepared in an ad hoc, heuristic way. In this talk, Sang Michael Xie will present principled approaches to improving and understanding language models centered on the pre-training data distribution. First, he will describe how to improve the efficiency of training multipurpose language models by optimizing the mixture of data sources with robust optimization. Second, he will discuss an efficient importance resampling method for selecting relevant data from trillion-token-scale web datasets for training a specialized model. Finally, he will introduce a first theoretical analysis of in-context learning, a key capability of language models to learn from examples in a textual prompt, that traces the capability back to modeling coherence structure in the pre-training data. Speaker Biography: Sang Michael Xie is a computer science PhD student at Stanford University advised by Percy Liang and Tengyu Ma. His research focuses on data-centric machine learning for language models, understanding pre-training and adaptation, and pre-training and self-training methods for robust machine learning. Xie was awarded a NDSEG Fellowship and was previously a student researcher at Google Brain. His work has been recognized as one of Scientific American ‘s World-Changing Ideas, published in flagship venues such as Science, and covered by media outlets including The New York Times, The Washington Post, Reuters, BBC News, IEEE Spectrum, and The Verge. Data Privacy in the Decentralized Era Amrita Roy Chowdhury, University of California San Diego View the recording >> Computer Science Seminar Series March 21, 2024 Abstract: Data is today generated on smart devices at the edge, shaping a decentralized data ecosystem comprised of multiple data owners (clients) and a service provider (server). Clients interact with the server with their personal data for specific services, while the server performs analysis on the joint dataset. However, the sensitive nature of the data involved, coupled with the inherent misalignment of incentives between clients and the server, breeds mutual distrust. Consequently, a key question arises: How can we facilitate private data analytics within a decentralized data ecosystem comprised of multiple distrusting parties? Amrita Roy Chowdhury’s research shows a way forward by designing systems that offer strong and provable privacy guarantees while preserving complete data functionality. She accomplishes this by systematically exploring the synergy between cryptography and differential privacy, exposing their rich interconnections in both theory and practice. In this talk , she will focus on two systems, CryptE and EIFFeL, which enable privacy-preserving query analytics and machine learning, respectively. Speaker Biography: Amrita Roy Chowdhury is a Computing Research Association and Computing Community Consortium Computing Innovation Fellow working with Kamalika Chaudhuri at the University of California San Diego. She graduated with her PhD from University of Wisconsin—Madison, where she was advised by Somesh Jha. Chowdhury completed her BE in computer science from the Indian Institute of Engineering Science and Technology, Shibpur, where she was awarded the President of India Gold Medal. Her work explores the synergy between differential privacy and cryptography through novel algorithms that expose the rich interconnections between the two areas, both in theory and practice. Chowdhury has been recognized as a Rising Star in Electrical Engineering and Computer Science in 2020 and 2021. She was also both a Facebook Fellowship finalist and selected as a Rising Star in Data Science by the University of Chicago in 2021. Learning and Planning with Relational Abstractions Tom Silver, Massachusetts Institute of Technology View the recording >> Computer Science Seminar Series March 20, 2024 Abstract: Decision-making in robotics domains is complicated by continuous state and action spaces, long horizons, and sparse feedback. One way to address these challenges is to perform bilevel planning, where decision-making is decomposed into reasoning about “what to do” (task planning) and “how to do it” (continuous optimization). Bilevel planning is powerful, but it requires multiple types of domain-specific abstractions that are often difficult to design by hand. In this talk, Tom Silver will give an overview of his work on learning these abstractions from data; this work represents the first unified system for learning all the abstractions needed for bilevel planning. In addition to learning to plan, he will also discuss planning to learn, where the robot uses planning to collect additional data that it can use to improve its abstractions. His long-term goal is to create a virtuous cycle where learning improves planning and planning improves learning, leading to a very general library of abstractions and a broadly competent robot. Speaker Biography: Tom Silver is a final-year PhD student at the Massachusetts Institute of Technology’s Department of Electrical Engineering and Computer Science, advised by Leslie Kaelbling and Josh Tenenbaum. His research is at the intersection of machine learning and planning with applications to robotics and often uses techniques from task and motion planning, program synthesis, and neuro-symbolic learning. Before graduate school, he was a researcher at Vicarious AI and received his BA with highest honors in computer science and mathematics from Harvard in 2016. Silver has also interned at Google Research (in brain robotics) and currently splits his time between MIT and the Boston Dynamics AI Institute. His work is supported by an NSF Fellowship and an MIT Presidential Fellowship. Towards Scalable Decentralized Systems Mingyuan Wang, University of California, Berkeley View the recording >> Computer Science Seminar Series March 19, 2024 Abstract: Decentralized systems enable mutually distrusting parties to collaboratively control a system; this fosters trust as no single corrupted party can break the system, while utility is ensured through collective participation. In recent years, decentralized systems have found many applications, particularly within the blockchain ecosystem. Traditionally, the robustness and security of a decentralized system increase with the number of participating parties. Consequently, the primary objective of decentralization is to scale the system to accommodate as many parties as possible. However, the existing framework for realizing threshold cryptography, the core cryptographic primitive enabling decentralization, still relies on interactive setup processes, posing significant scalability challenges in real-world scenarios. Additionally, it lacks the flexibility to handle advanced features such as weights, dynamism, and multiverse, which are highly desired in practice. In this talk, Mingyuan Wang will discuss his research work that proposes new techniques to address these issues, which pave the way for truly scalable decentralized cryptographic systems. He will conclude the talk by briefly discussing other research problems that he is interested in. Speaker Biography: Mingyuan Wang is a postdoctoral researcher at the University of California, Berkeley, hosted by Sanjam Garg. He received his PhD from Purdue University, where he was advised by Hemanta K. Maji. Wang is interested in cryptography and its interplay with theoretical computer science and security. His research covers a wide range of topics, including threshold cryptography, secure multiparty computation, leakage-resilient cryptography, and cryptographic applications in machine learning. His work has been published at top venues, such as Crypto, Eurocrypt, the IEEE Symposium on Security and Privacy, the ACM Conference on Computer and Communications Security, the Conference on Neural Information Processing Systems, the Theory of Cryptography Conference, the IEEE International Symposium on Information Theory, and more. Knowledge-Rich Language Systems in a Dynamic World Eunsol Choi, University of Texas at Austin View the recording >> Computer Science Seminar Series March 15, 2024 Abstract: Natural language provides an intuitive and powerful interface to access knowledge at scale. Modern language systems draw information from two rich knowledge sources: (1) information stored in their parameters during massive pretraining and (2) documents retrieved at inference time. Yet we are far from building systems that can reliably provide information from such knowledge sources. In this talk, Eunsol Choi will discuss paths for more robust systems. In the first part of her talk, she will present a module for scaling retrieval-based knowledge augmentation, learning a compressor that maps retrieved documents into textual summaries prior to in-context integration; this not only reduces the computational costs but also filters irrelevant or incorrect information. In the second half of her talk, she will discuss the challenges of updating knowledge stored in model parameters and propose a method to prevent models from reciting outdated information by identifying facts that are prone to rapid change. She will conclude her talk by proposing an interactive system that can elicit information from users when needed. Speaker Biography: Eunsol Choi is an assistant professor of computer science at the University of Texas (UT) at Austin. Prior to teaching at UT, she spent a year at Google AI as a visiting researcher. Choi’s research area spans natural language processing and machine learning; she is particularly interested in interpreting and reasoning about text in a dynamic, real-world context. She is a recipient of a Meta Research PhD Fellowship, a Google Faculty Research Award, a Sony Research Award, and an Outstanding Paper Award at the Conference on Empirical Methods in Natural Language Processing. She received a PhD in computer science and engineering from the University of Washington and a BA in mathematics and computer science from Cornell University. Foundations of Multisensory Artificial Intelligence Paul Liang, Carnegie Mellon University View the recording >> Computer Science Seminar Series March 12, 2024 Abstract: Building multisensory AI systems that learn from multiple sensory inputs—such as text, speech, video, real-world sensors, wearable devices, and medical data—holds great promise for many scientific areas in terms of practical benefits, such as supporting human health and well-being, enabling multimedia content processing, and enhancing real-world autonomous agents. In this talk, Paul Liang will discuss his research on the machine learning principles of multisensory intelligence, as well as practical methods for building multisensory foundation models over many modalities and tasks. In the first half of the seminar, Liang will present a theoretical framework formalizing how modalities interact with each other to give rise to new information for a task. These interactions are the basic building blocks in all multimodal problems and their quantification enables users to understand multimodal datasets and design principled approaches to learn these interactions. In the second half of the seminar, Liang will present his work in cross-modal attention and the multimodal transformer architectures that now underpin many of today’s multimodal foundation models. Finally, he will discuss his collaborative efforts in scaling AI to many modalities and tasks for real-world impact on affective computing, mental health, and cancer prognosis. Speaker Biography: Paul Liang is a PhD student in machine learning at Carnegie Mellon University, advised by Louis-Philippe Morency and Ruslan Salakhutdinov. He studies the machine learning foundations of multisensory intelligence to design practical AI systems that integrate, learn from, and interact with a diverse range of real-world sensory modalities. His work has been applied in affective computing, mental health, pathology, and robotics. He is a recipient of the Siebel Scholars Award, the Waibel Presidential Fellowship, a Meta Research PhD Fellowship, the Center for Machine Learning and Health Fellowship and was named a Rising Star in data science. He has additionally received three Best Paper or Honorable Mention Awards at International Conference on Multimodal Interaction and Conference on Neural Information Processing Systems workshops. Outside of research, Liang received the Alan J. Perlis Graduate Student Teaching Award for instructing courses on multimodal machine learning and advising students around the world in directed research. Hardware-Aware Efficient Primitives for Machine Learning Dan Fu, Stanford University View the recording >> Computer Science Seminar Series March 7, 2024 Abstract: Efficiency is increasingly tied to quality in machine learning, with more efficient training algorithms leading to more powerful models. However, today’s most popular machine learning models are built on asymptotically inefficient primitives. For example, attention in transformers scales quadratically with input size, while multilayer perceptrons scale quadratically with model dimension. In this talk, Dan Fu discusses his work on improving the efficiency of core primitives in machine learning, with an emphasis on hardware-aware algorithms and long-context applications. First, he focuses on replacing attention with gated state space models (SSMs) and convolutions, which scale sub-quadratically in context length. He describes the H3 (Hungry Hungry Hippos) architecture, a gated SSM architecture that matches transformers in quality up to 3B parameters and achieves 2.4x faster inference. Second, he focuses on developing hardware-aware algorithms for SSMs and convolutions; he describes FlashFFTConv, a fast algorithm for computing SSMs and convolutions on GPU by optimizing the fast Fourier transform (FFT). FlashFFTConv yields up to 7x speedup and 5x memory savings, even over vendor solutions from NVIDIA. Third, he will briefly touch on how these same techniques can also be used to develop sub-quadratic scaling in the model dimension. He will describe Monarch Mixer, which uses a generalization of the FFT to achieve sub-quadratic scaling in both sequence length and model dimension. Throughout the talk, he will give examples of how these ideas are beginning to take hold, with gated SSMs and their variants now leading to state-of-the-art performance in long-context language models, embedding models, and DNA foundation models. Speaker Biography: Dan Fu is a PhD student in the Computer Science Department at Stanford University, where he is co-advised by Christopher Ré and Kayvon Fatahalian. His research interests are at the intersection of systems and machine learning. Recently, Fu has focused on developing algorithms and architectures to make machine learning more efficient, especially for enabling longer-context applications. His research has appeared as oral and spotlight presentations at the Conference on Neural Information Processing Systems, the International Conference on Machine Learning, and the International Conference on Learning Representations; he additionally received the Best Student Paper Runner-Up Award at the Conference on Uncertainty in Artificial Intelligence and has been supported by a National Defense Science and Engineering Graduate Fellowship. Learning to See the World in 3D Ayush Tewari, Massachusetts Institute of Technology View the recording >> Computer Science Seminar Series March 6, 2024 Abstract: Humans can effortlessly construct rich mental representations of the 3D world from sparse input, such as a single image. This is a core aspect of intelligence that helps us understand and interact with our surroundings and with each other. Ayush Tewari’s research aims to build similar computational models: artificial intelligence methods that can perceive properties of the 3D structured world from images and videos. Despite remarkable progress in 2D computer vision, 3D perception remains an open problem due to some unique challenges, such as limited 3D training data and uncertainties in reconstruction. In this talk, Tewari will discuss these challenges and explain how his research addresses them by posing vision as an inverse problem and by designing machine learning models with physics-inspired inductive biases. He will demonstrate techniques for reconstructing 3D faces and objects and for reasoning about uncertainties in scene reconstruction using generative models. He will then discuss how these efforts advance scalable and generalizable visual perception and how they advance application domains such as robotics and computer graphics. Speaker Biography: Ayush Tewari is a postdoctoral researcher at the Massachusetts Institute of Technology’s Computer Science and Artificial Intelligence Laboratory with William Freeman, Vincent Sitzmann, and Joshua Tenenbaum. He previously completed his PhD at the Max Planck Institute for Informatics, where he was advised by Christian Theobalt. His research interests lie at the intersection of computer vision, computer graphics, and machine learning, focusing on 3D perception and its applications. Tewari was awarded the Otto Hahn Medal from the Max Planck Society for his scientific contributions as a PhD student. Integrative Modeling of Multiscale Single-Cell Spatial Epigenome Jian Ma, Carnegie Mellon University View the recording >> Computer Science Seminar Series March 5, 2024 Abstract: Despite significant advancements in high-throughput data acquisition in genomics and cell biology, our understanding of the diverse cell types within the human body remains limited. Particularly, the principles governing intracellular molecular spatial organization and cellular spatial organization within complex tissues are still largely unclear. A major challenge lies in developing computational methods capable of integrating heterogeneous and multiscale molecular, cellular, and tissue information. In this talk, Jian Ma will discuss his recent work on creating integrative approaches for single-cell spatial epigenomics and transcriptomics. These methods hold the potential to reveal new insights into fundamental genome structure and cellular function, as well as the spatial organization of cells within complex tissues, across a wide range of biological contexts in health and disease. Speaker Biography: Jian Ma is the Ray and Stephanie Lane Professor of Computational Biology at Carnegie Mellon University’s School of Computer Science. His lab focuses on developing computational methods to study the structure and function of the human genome and cellular organization and their implications for evolution, health, and disease. He currently leads a multidisciplinary NIH center as part of the NIH 4D Nucleome Program. His recent work has been supported by the NIH, the NSF, the Chan Zuckerberg Initiative , Google, and the Mark Foundation. He has received several awards, including an NSF CAREER Award and a Guggenheim Fellowship in computer science, and is an elected fellow of the American Association for the Advancement of Science. Improving, Evaluating, and Detecting Long-Form LLM-Generated Text Mohit Iyyer, University of Massachusetts Amherst View the recording >> Computer Science Seminar Series March 1, 2024 Abstract: Recent advances in large language models have enabled them to process texts exceeding 100,000 tokens in length, fueling demand for long-form language processing tasks such as the summarization or translation of books. However, LLMs struggle to take full advantage of the information within such long contexts, which contributes to factually incorrect and incoherent text generation. In this talk, Mohit Iyyer will first demonstrate an issue that plagues even modern LLMs: their tendency to assign high probability to implausible long-form continuations of their input. He will then describe a contrastive sequence-level ranking model that mitigates this problem at decoding time and that can also be adapted to the reinforcement learning from human feedback alignment paradigm. Next, he will consider the growing problem of long-form evaluation : As the length of the inputs and outputs of long-form tasks grows, how do we even measure progress (via both humans and machines)? He proposes a high-level framework that first decomposes a long-form text into simpler atomic units before then evaluating each unit on a specific aspect. He demonstrates the framework’s effectiveness at evaluating factuality and coherence on tasks such as biography generation and book summarization. He will also discuss the rapid proliferation of LLM-generated long-form text, which plagues not only evaluation (e.g., via Mechanical Turkers using ChatGPT to complete tasks) but also society as a whole, and he will describe novel watermarking strategies to detect such text. Finally, he will conclude by discussing his future research vision, which aims to extend long-form language processing to multilingual, multimodal, and collaborative human-centered settings. Speaker Biography: Mohit Iyyer is an associate professor in computer science at the University of Massachusetts Amherst, with a primary research interest in natural language generation. He is the recipient of Best Paper Awards at the 2016 and 2018 Annual Conferences of the North American Chapter of the Association for Computational Linguistics, an Outstanding Paper Award at the 2023 Conference of the European Chapter of the Association for Computational Linguistics, and a Best Demo Award at the 2015 Conference on Neural Information Processing Systems; he also received the 2022 Samsung AI Researcher of the Year award. Iyyer obtained his PhD in computer science from the University of Maryland, College Park in 2017 and spent the following year as a researcher at the Allen Institute for AI. Stochastic Computer Graphics Silvia Sellán, University of Toronto View the recording >> Computer Science Seminar Series February 29, 2024 Abstract: Computer graphics research has long been dominated by the interests of large film, television, and social media companies, forcing other, more safety-critical applications (e.g., medicine, engineering, security) to repurpose graphics algorithms originally designed for entertainment. In this talk, Silvia Sellán will advocate for a perspective shift in this field that allows researchers to design algorithms directly for these safety-critical application realms. She will show that this begins by reinterpreting traditional graphics tasks (e.g., 3D modeling and reconstruction) from a statistical lens and quantifying the uncertainty in algorithmic outputs, as exemplified by the research she has conducted for the past five years. She will end by mentioning several ongoing and future research directions that carry this statistical lens to entirely new problems in graphics and vision and into specific applications. Speaker Biography: Sellán is a fifth-year computer science PhD student at the University of Toronto, working in computer graphics and geometry processing. She is a Vanier Doctoral Scholar, an Adobe Research Fellow, and the winner of the 2021 University of Toronto Arts & Science Dean’s Doctoral Excellence Scholarship. She has interned twice at Adobe Research and twice at the Fields Institute of Mathematics. She is also a founder and organizer of the Toronto Geometry Colloquium and a member of the ACM Community Group for Women in Computer Graphics Research. Decision-Making with Internet-Scale Knowledge Sherry Yang, University of California, Berkeley View the recording >> Computer Science Seminar Series February 28, 2024 Abstract: Machine learning models pre-trained on internet data have acquired broad knowledge about the world, but struggle to solve complex tasks that require extended reasoning and planning. Sequential decision-making, on the other hand, has empowered AlphaGo’s superhuman performance, but lacks visual, language, and physical knowledge about the world. In this talk, Sherry Yang will present her research towards enabling decision making with internet-scale knowledge. First, she will illustrate how language models and video generation are unified interfaces that can integrate internet knowledge and represent diverse tasks, enabling the creation of a generative simulator to support real-world decision-making. Second, she will discuss her work on designing decision-making algorithms that can take advantage of generative language and video models as agents and environments. Combining pre-trained models with decision-making algorithms can effectively enable a wide range of applications such as developing chatbots, learning robot policies, and discovering novel materials. Speaker Biography: Sherry Yang is a final-year PhD student at the University of California, Berkeley, advised by Pieter Abbeel; she is also a senior research scientist at Google DeepMind. Her research aims to develop machine learning models with internet-scale knowledge to make better-than-human decisions. To this end, she has developed techniques for generative modeling and representation learning from large-scale vision, language, and structured data, coupled with developing algorithms for sequential decision-making such as imitation learning, planning, and reinforcement learning. Yang initiated and led the Foundation Models for Decision Making workshop at the 2022 and 2023 Conferences on Neural Information Processing Systems, bringing together research communities in vision, language, planning, and reinforcement learning to solve complex decision-making tasks at scale. Before her current role, Yang received her bachelor’s and master’s degrees from the Massachusetts Institute of Technology, where she was advised by Patrick Winston and Julian Shun. Building Planetary-Scale Collaborative Intelligence Sai Praneeth Karimireddy, University of California, Berkeley View the recording >> Computer Science Seminar Series February 22, 2024 Abstract: Today, access to high-quality data has become the key bottleneck to deploying machine learning. Often, the data that is most valuable is locked away in inaccessible silos due to unfavorable incentives and ethical or legal restrictions. This is starkly evident in health care, where such barriers have led to highly biased and underperforming tools. In his talk, Sai Praneeth Karimireddy will describe how collaborative systems, such as federated learning, provide a natural solution; they can remove barriers to data sharing by respecting the privacy and interests of the data providers. Yet for these systems to truly succeed, three fundamental challenges must be confronted: These systems need to 1) be efficient and scale to large networks, 2) provide reliable and trustworthy training and predictions, and 3) manage the divergent goals and interests of the participants. Karimireddy will discuss how tools from optimization, statistics, and economics can be leveraged to address these challenges. Speaker Biography: Sai Praneeth Karimireddy is a postdoctoral researcher at the University of California, Berkeley with Mike I. Jordan . Karimireddy obtained his undergraduate degree from the Indian Institute of Technology Delhi and his PhD at the Swiss Federal Institute of Technology Lausanne (EPFL) with Martin Jaggi . His research builds large-scale machine learning systems for equitable and collaborative intelligence and designs novel algorithms that can robustly and privately learn over distributed data (i.e., edge, federated, and decentralized learning). He also closely engages with industry and public health organizations (e.g., Doctors Without Borders , the Red Cross , the Cancer Registry of Norway ) to translate his research into practice. His work has previously been deployed across industry by Meta , Google , OpenAI , and Owkin and has been awarded with the EPFL Patrick Denantes Memorial Prize for the best computer science thesis, the Dimitris N. Chorafas Foundation Award for exceptional applied research, an EPFL thesis distinction award, a Swiss National Science Foundation fellowship , and best paper awards at the International Workshop on Federated Learning for User Privacy and Data Confidentiality at the 2021 International Conference on Machine Learning and the International Workshop on Federated Learning: Recent Advances and New Challenges at the Thirty-Sixth Annual Conference on Neural Information Processing Systems. Investigate and Mitigate the Attacks Caused by Out-of-Band Signals Xiali Hei, University of Louisiana at Lafayette View the recording >> Institute for Assured Autonomy & Computer Science Seminar Series February 20, 2024 Abstract: Sensing and actuation systems are entrusted with increasing intelligence to perceive and react to the environment, but their reliability often relies on the trustworthiness of sensors. As process automation and robotics keep evolving, sensing methods such as pressure, temperature, and motion sensing are extensively used in conventional systems and rapidly emerging applications. This talk aims to investigate the threats incurred by the out-of-band signals and discuss the low-cost defense methods against physical injection attacks on sensors. Hei will present her paper results from the USENIX Security Symposium, ACM Conference on Computer and Communications Security (CCS) , ACM Asia CSS , Secure and Trustworthy Deep Learning Systems Workshop, Joint Workshop on CPS & IoT Security and Privacy , and European Alliance for Innovation’s International Conference on Security and Privacy in Cyber-Physical Systems and Smart Vehicles . Speaker Biography: Xiali “Sharon” Hei has been an Alfred and Helen M. Lamson Endowed Associate Professor in the School of Computing and Informatics at the University of Louisiana at Lafayette since August, 2023. She was previously an Alfred and Helen M. Lamson Endowed Assistant Professor from August 2017 to July 2023. Prior to joining the University of Louisiana at Lafayette, she was an assistant professor at Delaware State University from 2015–2017 and an assistant professor at Frostburg State University from 2014–2015. Hei has received a number of awards, including an Alfred and Helen M. Lamson Endowed Professorship; an Outstanding Achievement Award in Externally Funded Research; numerous recognitions from the NSF, including a Track 4 Faculty Fellowship, a Secure and Trustworthy Cyberspace award, a Major Research Instrumentation award, an Established Program to Stimulate Competitive Research RII Track 1 award, a Computer and Information Science and Engineering Research Initiation Initiative award; a Meta research award; funding from the Lousiana Board of Regents Support Fund; a Delaware Economic Development Office grant; a Best Paper Award at the European Alliance for Innovation’s International Conference on Security and Privacy in Cyber-Physical Systems and Smart Vehicles; a Best Poster Runner-Up Award at the 2014 ACM International Symposium on Mobile Ad Hoc Networking and Computing; a Dissertation Completion Fellowship; the Bronze Award Best Graduate Project in Future of Computing Competition, and more. Her papers have been published at venues such as the USENIX Security Symposium, t he ACM Conference on Computer and Communications Security , the Institute of Electrical and Electronics Engineers ( IEEE) International Conference on Computer Communications (ICC) , the IEEE European Symposium on Security and Privacy (EuroS&P) , the International Symposium on Research in Attacks, Intrusions and Defenses, and the ACM Asia Conference on Computer and Communications Security . Hei is a TPC member of the USENIX Security Symposium, IEEE EuroS&P, PST, the IEEE Global Communications Conference , SafeThings, AutoSec, IEEE ICC, the International Conference on Wireless Artificial Intelligent Computing Systems and Applications, and more. She has also been an IEEE senior member since 2019. Hei earned a BS in electrical engineering from Xi’an Jiaotong University and an MS in software engineering from Tsinghua University. Replicability in Machine Learning Jessica Sorrell, University of Pennsylvania View the recording >> Computer Science Seminar Series February 15, 2024 Abstract: Replicability is vital to ensuring scientific conclusions are reliable, but failures of replicability have been a major issue in nearly all scientific areas of study; machine learning is no exception. While failures of replicability in machine learning are multifactorial, one obstacle to replication efforts is the ambiguity in whether or not a replication effort was successful when many good models exist for a task. In this talk, we will discuss a new formalization of replicability for batch and reinforcement learning algorithms and demonstrate how to solve fundamental tasks in learning under the constraints of replicability. We will also discuss how replicability relates to other algorithmic desiderata in responsible computing, such as differential privacy. Speaker Biography: Jessica Sorrell is a postdoctoral researcher at the University of Pennsylvania, where she works with Aaron Roth and Michael Kearns. She completed her PhD at the University of California San Diego, advised by Russell Impagliazzo and Daniele Micciancio. She is broadly interested in the theoretical foundations of responsible computing and her work spans a variety of pressing issues in machine learning, such as replicability, privacy, and fairness. Towards More Human-Like Learning in Machines: Bridging the Data and Generalization Gaps Brenden M. Lake, New York University View the recording >> Computer Science Seminar Series February 12, 2024 Abstract: There is an enormous data gap between how AI systems and children learn language: The best LLMs now learn language from text with a word count in the trillions, whereas it would take a child roughly 100K years to reach those numbers through speech. There is also a clear generalization gap: Whereas machines struggle with systematic generalization, people excel. For instance, once a child learns how to “skip,” they immediately know how to “skip twice” or “skip around the room with their hands up” due to their compositional skills. In this talk, Brenden Lake will describe two case studies in addressing these gaps. The first addresses the data gap, in which deep neural networks were trained from scratch, not on large-scale data from the web, but through the eyes and ears of a single child. Using head-mounted video recordings from a child, this study shows how deep neural networks can acquire many word-referent mappings, generalize to novel visual referents, and achieve multi-modal alignment. The results demonstrate how today’s AI models are capable of learning key aspects of children’s early knowledge from realistic input. The second case study addresses the generalization gap. Can neural networks capture human-like systematic generalization? This study addresses a 35-year-old debate catalyzed by Fodor and Pylyshyn’s classic article, which argued that standard neural networks are not viable models of the mind because they lack systematic compositionality—the algebraic ability to understand and produce novel combinations from known components. This study shows how neural networks can achieve humanlike systematic generalization when trained through meta-learning for compositionality (MLC), a new method for optimizing the compositional skills of neural networks through practice. With MLC, a neural network can match human performance and solve several machine learning benchmarks. Given this work, we’ll discuss the paths forward for building machines that learn, generalize, and interact in more humanlike ways based on more natural input. Speaker Biography: Brenden M. Lake is an assistant professor of psychology and data science at New York University. He received his MS and BS in symbolic systems from Stanford University in 2009 and his PhD in cognitive science from the Massachusetts Institute of Technology in 2014. Lake was a postdoctoral data science fellow at NYU from 2014–2017. He is a recipient of the Robert J. Glushko Prize for Outstanding Doctoral Dissertation in Cognitive Science, he was named an Innovator Under 35 by MIT Technology Review , and his research was selected by Scientific American as one of the 10 most important advances of 2016. Lake’s research focuses on computational problems that are easier for people than they are for machines, such as learning new concepts, creating new concepts, learning to learn, and asking questions. Modern Algorithms for Massive Graphs: Structure and Compression Ben Moseley, Carnegie Mellon University View the recording >> Computer Science Seminar Series February 1, 2024 Abstract: This talk will discuss the area of algorithms with predictions, also known as learning-augmented algorithms. These methods parameterize algorithms with machine-learned predictions, enabling the algorithms to tailor their decisions to input distributions and to allow for improved performance on runtime, space, or solution quality. This talk will discuss recent developments on how to leverage machine-learned predictions to improve the runtime efficiency of algorithms for optimization and data structures. The talk will also discuss how to achieve “instance-optimal” algorithms when the predictions are accurate and the algorithm’s performance gracefully degrades when there are errors in the predicted advice. The talk will illustrate via examples such as bipartite matching the potential of the area to realize significant performance improvements for algorithm efficiency. Speaker Biography: Ben Moseley is the Carnegie-Bosch Associate Professor of Operations Research at Carnegie Mellon University and is a consulting scientist at Relational AI. He obtained his PhD from the University of Illinois. During his career, his papers have won best paper awards at IPDPS (2015), SPAA (2013), and SODA (2010). His papers have been recognized as top publications with honors such as Oral Presentations at NeurIPS (2021, 2017) and NeurIPS Spotlight Papers (2023, 2018). He has served as area chair for ICML, ICLR, and NeurIPS every year since 2020 and has been on many program committees, including SODA (2022, 2018), ESA (2017), and SPAA (2024, 2022, 2021, 2016). He was an associate editor for IEEE Transactions on Knowledge and Data Engineering from 2018–2022 and has served as associate editor of Operations Research Letters since 2017. He has won an NSF CAREER Award, two Google Research Faculty Awards, a Yahoo ACE Award, and an Infor faculty award. He was selected as a Top 50 Undergraduate Professor by Poets & Quants. His research interests broadly include algorithms, machine learning, and discrete optimization. He is currently excited about robustly incorporating machine learning into decision-making processes. Normativity and the AI Alignment Problem Gillian Hadfield, University of Toronto, School of Law View the recording >> Computer Science Seminar Series January 25, 2024 Abstract: The alignment problem in AI is currently framed in a variety of ways: It is the challenge of building AI systems that do as their designers intend, or as their users prefer, or as would benefit society. In this talk Gillian Hadfield connects the AI alignment problem to the far more general problem of how humans organize cooperation societies. From the perspective of an economist and legal scholar, alignment is the problem of how to organize society to maximize human well-being—however that is defined. Hadfield will argue that “solving” the AI alignment problem is better thought of as the problem of how to integrate AI systems, especially agentic systems, into our human normative systems. She will present results from collaborations with computer scientists that begin the study of how to build normatively competent AI systems—AI that can read and participate in human normative systems—and normative infrastructure that can support AI’s normative competence. Probabilistic Methods for Designing Functional Protein Structures Brian Trippe, Columbia University Computer Science Seminar Series January 23, 2024 Abstract: The biochemical functions of proteins, such as catalyzing a chemical reaction or binding to a virus, are typically conferred by the geometry of only a handful of atoms. This arrangement of atoms, known as a motif, is structurally supported by the rest of the protein, referred to as a scaffold. A central task in protein design is to identify a diverse set of stabilizing scaffolds to support a motif known or theorized to confer function. This long-standing challenge is known as the motif-scaffolding problem. In this talk, Brian Trippe describes a statistical approach he has developed to address the motif-scaffolding problem. His approach involves (1) estimating a distribution supported on realizable protein structures and (2) sampling scaffolds from this distribution conditioned on a motif. For the first step, he adapts diffusion generative models to fit example protein structures from nature. For the second step, he develops sequential Monte Carlo algorithms to sample from the conditional distributions of these models. He finally describes how, with experimental and computational collaborators, he has generalized and scaled this approach to generate and experimentally validate hundreds of proteins with various functional specifications. Speaker Biography: Brian Trippe is a postdoctoral fellow at Columbia University in the Department of Statistics and a visiting researcher at the Institute for Protein Design at the University of Washington. He completed his PhD in computational and systems biology at the Massachusetts Institute of Technology, where he worked on Bayesian methods for inference in high-dimensional linear models. In his research, Trippe develops statistical machine learning methods to address challenges in biotechnology and medicine, with a focus on generative modeling and inference algorithms for protein engineering. Towards an Open Mobile Networking Ecosystem Mahesh Marina, University of Edinburgh View the recording >> Computer Science Seminar Series January 18, 2024 Abstract: Mobile (cellular) networks traditionally have been closed systems, developed as vertically integrated, black-box appliances by a few equipment vendors and deployed by a handful of national-scale mobile network operators in each country—all in all, a small ecosystem. However, we have witnessed a radical transformation in the design and deployment of mobile networking systems in the recent past that reflects a path toward greater openness. In this talk, Marina will give his perspective on the key drivers, economic and beyond, behind this trend and the main enablers for this transformation. He will complement this by outlining his key research contributions in this direction. Further, he will highlight two of his recent works: (1) on rearchitecting the mobile core control plane for efficient cloud-native operation and to be more open (i.e., better suited for multi-vendor realization); and (2) on radio access network root cause analysis as a key challenge for Open RAN, as well as a compelling use case of the AI-powered and data-driven operations it enables. Speaker Biography: Mahesh Marina is a professor in the School of Informatics at the University of Edinburgh, where he leads the Networked Systems Research Group. He is currently spending his sabbatical time at the Johns Hopkins University’s Department of Computer Science as a visiting professor. Previously, Marina was a Turing Fellow at the Alan Turing Institute, the UK’s national institute for data science and AI, for five years, 2018–2023; he also served as the director of the Institute for Computing Systems Architecture within Informatics@Edinburgh for four years, until July 2022. Prior to joining the University of Edinburgh, Marina had a two-year postdoctoral stint at the UCLA Computer Science Department after earning his PhD in computer science from the State University of New York at Stony Brook. He has previously held visiting researcher positions at ETH Zurich and at Ofcom, the UK’s telecommunications regulator, at its headquarters in London. Marina is an ACM Distinguished Member and an IEEE Senior Member. Securing 5G Against Fragile and Malicious Infrastructure Alex Marder, Johns Hopkins University View the recording >> Institute for Assured Autonomy & Computer Science Seminar Series January 16, 2024 Abstract: In early 2020, the U.S. government revealed its belief that China might be able to eavesdrop on 5G communications through Huawei network equipment. This has enormous ramifications for DOD and State Department communications overseas, since these backdoors could provide our adversaries with information that allows them to glean insights into operations or harm personnel. Later that same year, wired and wireless networks in the greater Nashville area failed when a bomb damaged a single network facility. The outage affected nearly every aspect of modern society, including grounding flights, disrupting economic activity, and disconnecting 911. These two events highlight the enormous challenge of securing critical communications: We need to secure our communications against threats within the telecommunications infrastructure and secure it from external attack. This talk will discuss both of these challenges. First, Marder will use the Nashville outage as a blueprint to show that it remains surprisingly easy for attackers to induce large-scale communications outages around the U.S. without any insider information or specialized access. Second, he will discuss innovative methods for identifying and circumventing the potential threats placed by nation-state adversaries within the infrastructure, along with methods for ensuring that communications only traverse benign infrastructure. Speaker Biography: Alex Marder is an assistant professor of computer science at Johns Hopkins University and a member of the Institute for Assured Autonomy. Marder’s research covers a wide breadth of networking areas, including the use of empirical analyses and machine learning to evaluate and improve the security and performance of wired and wireless networks. His current work leverages a deep understanding of network architecture and deployment to design secure 5G communication networks for the Department of Defense, reveal security weaknesses in domestic internet access networks, and provide a better understanding of broadband inequity. He received a BS from Brandeis University and a PhD from the University of Pennsylvania. Prior to joining Johns Hopkins, he was a research scientist at CAIDA at UC San Diego. Computational Methods for Human Networks and High-Stakes Decisions Serina Yongchen Chang, Stanford University View the recording >> Computer Science Speaker Series December 5, 2023 Abstract: In an interconnected world, effective policymaking increasingly relies on understanding large-scale human networks. However, there are many challenges to understanding networks and how they impact decision-making, including (1) how to infer human networks, which are typically unobserved, from data; (2) how to model complex processes, such as disease spread, over networks and inform decision-making; and (3) how to estimate the impacts of decisions, in turn, on human networks. In this talk, I’ll discuss how I’ve addressed each of these challenges in my research. I’ll focus mainly on COVID-19 pandemic response as a concrete application, where we’ve developed new methods for network inference and epidemiological modeling, and have deployed decision-support tools for policymakers. I’ll also touch on other network-driven challenges, including political polarization and supply chain resilience. Formal Verification of Financial Algorithms with Imandra Grant Passmore, Imandra Inc. View the recording >> Institute for Assured Autonomy & Computer Science Seminar Series November 14, 2023 Abstract: Many deep issues plaguing today’s financial markets are symptoms of a fundamental problem: The complexity of algorithms underlying modern finance has significantly outpaced the power of traditional tools used to design and regulate them. At Imandra, we have pioneered the application of formal verification to financial markets, where firms like Goldman Sachs, Itiviti, and OneChronos already rely upon Imandra’s algorithm governance tools for the design, regulation, and calibration of many of their most complex algorithms. With a focus on financial infrastructure (e.g., the matching logics of national exchanges and dark pools), we will describe the landscape and illustrate our Imandra system on a number of real-world examples. We’ll sketch many open problems and future directions along the way. Speaker Biography: Grant Passmore is the co-founder and co-CEO of Imandra Inc. Passmore is a widely published researcher in formal verification and symbolic Al and has more than fifteen years of industrial formal verification experience. He has been a key contributor to the safety verification of algorithms at Cambridge, Carnegie Mellon, Edinburgh, Microsoft Research, and SRI. He earned his PhD on automated theorem proving in algebraic geometry from the University of Edinburgh, is a graduate of UT Austin (BA in mathematics) and the Mathematical Research Institute in the Netherlands (master class in mathematical logic), and is a life member of Clare Hall, University of Cambridge. Side Channel Attacks: Lessons Learned or Troubles Ahead? Daniel Genkin, Georgia Institute of Technology View the recording >> Computer Science Seminar Series October 19, 2023 Abstract: The security and architecture communities will remember the past five years as the era of side channels. Starting from Spectre and Meltdown, time and again we have seen how basic performance-improving features can be exploited to violate fundamental security guarantees. Making things worse, the rise of side channels points to a much larger problem, namely the presence of large gaps in the hardware-software execution contract on modern hardware. In this talk, I will give an overview of this gap, in terms of both security and performance. First, I will give a high-level survey on speculative execution attacks such as Spectre and Meltdown. I will then talk about how speculative attacks are still a threat to both kernel and browser isolation primitives, highlighting new issues on emerging architectures. Next, from the performance perspective, I will discuss new techniques for microarchitectural code optimizations, with an emphasis on cryptographic protocols and other compute-heavy workloads. Here I will show how seemingly simple, functionally equivalent code modifications can lead to significant changes in the underlying microarchitectural behavior, resulting in dramatic performance improvements. The talk will be interactive and include attack demonstrations. Speaker Biography: Daniel Genkin is an Alan and Anne Taetle Early Career Associate Professor at the School of Cybersecurity and Privacy at Georgia Tech. Daniel’s research interests are in hardware and system security, with particular focus on side channel attacks and defenses. Daniel’s work has won the Distinguished Paper Award at IEEE Security and Privacy, an IEEE Micro Top Pick, and the Black Hat Pwnie Awards, as well as top-3 paper awards in multiple conferences. Most recently, Daniel has been part of the team performing the first analysis of speculative and transient execution, resulting in the discovery of Spectre, Meltdown, and follow-ups. Daniel has a PhD in computer science from the Technion Israel’s Institute of Technology and was a postdoctoral fellow at the University of Pennsylvania and the University of Maryland. Towards Rigorously Tested & Reliable Machine Learning for Health Michael Oberst, Carnegie Mellon University View the recording >> Institute for Assured Autonomy & Computer Science Seminar Series October 17, 2023 Abstract: How do we make machine learning as rigorously tested and reliable as any medication or diagnostic test? ML has the potential to improve decision-making in health care, from predicting treatment effectiveness to diagnosing disease. However, standard retrospective evaluations can give a misleading sense for how well models will perform in practice. Evaluation of ML-derived treatment policies can be biased when using observational data, and predictive models that perform well in one hospital may perform poorly in another. In this talk, I will introduce new tools to proactively assess and improve the reliability of machine learning in healthcare. A central theme will be the application of external knowledge, including review of patient records, incorporation of limited clinical trial data, and interpretable stress tests. Throughout, I will discuss how evaluation can directly inform model design. Speaker Biography: Michael Oberst is an incoming assistant professor of computer science at Johns Hopkins and is currently a postdoc in the Machine Learning Department at Carnegie Mellon University. His research focuses on making sure that machine learning in health care is safe and effective, using tools from causal inference and statistics. His work has been published at a range of machine learning venues (NeurIPS, ICML, AISTATS, KDD), including work with clinical collaborators from Mass General Brigham, NYU Langone, and Beth Israel Deaconess Medical Center. He has also worked on clinical applications of machine learning, including work on learning effective antibiotic treatment policies (published in Science Translational Medicine ). He earned his undergraduate degree in Statistics at Harvard and his PhD in computer science at MIT. Archive From the calendar years 1997–2023. Spring 2023 Fall 2022 Summer 2022 Spring 2022 Fall 2021 Summer 2021 Spring 2021 Fall 2020 Spring 2020 Fall 2019 Summer 2019 Spring 2019 Fall 2018 Summer 2018 Spring 2018 Fall 2017 Summer 2017 Spring 2017 Fall 2016 Summer 2016 Spring 2016 Fall 2015 Spring 2015 Fall 2014 Spring 2014 Fall 2013 Spring 2013 Fall 2012 Spring 2012 Fall 2011 Spring 2011 Fall 2010 Spring 2010 Fall 2009 Spring 2009 Fall 2008 Spring 2008 Fall 2007 Spring 2007 Fall 2006 Spring 2006 Fall 2005 Spring 2005 Fall 2004 Spring 2004 Fall 2003 Spring 2003 Fall 2002 Spring 2002 Spring 2001 Fall 2000 Spring 2000 Fall 1999 Spring 1999 Fall 1998 Spring 1998 Fall 1997 Summer 1997 Spring 1997 Stay Connected Facebook Twitter Instagram YouTube LinkedIn Open site alert Department of Computer Science Address 3400 North Charles Street Baltimore , MD 21218 Get Directions Contact Email: contactus@cs.jhu.edu Footer Navigation Apply Now! ﻿ Whiting School of Engineering ﻿ Johns Hopkins University ﻿ Legal Navigation Privacy Statement ﻿ Accessibility ﻿ University Policies ﻿ Copyright Compliance Policy ﻿ 2024 Johns Hopkins University . All rights reserved. Site Menu Site Navigation About Message from the Department Head Diversity and Inclusion Employment Opportunities Academic Programs Accreditation & Enrollment Undergraduate Studies Graduate Studies Combined Bachelor’s/Master’s Academic Integrity Code Research Theory & Programming Languages Systems & Networking Computational Biology & Medicine Information Security Natural Language Processing Machine Learning, AI, & Data Science Robotics, Vision, & Graphics Human-Computer Interaction Computer-Assisted Medicine People Faculty Joint, Affiliate, & Research Faculty Staff PhD Students External Advisory Board News CS Newsletter Events Department Seminars Join our Seminar Listserv CS Distinguished Lecture Series Alumni & Giving Utility Navigation Request Info ﻿ Apply ﻿ Give ﻿ Secondary Navigation CS IT Support Close ﻿"
}